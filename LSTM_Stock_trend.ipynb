{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation, Dense , Dropout\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import EarlyStopping , LearningRateScheduler\n",
    "import keras.backend as K\n",
    "from keras.initializers import RandomUniform\n",
    "from keras import metrics , regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6628, 10)\n"
     ]
    }
   ],
   "source": [
    "def splitData(X,rate):\n",
    "    train = X[:int(X.shape[0]*rate)]\n",
    "    val = X[int(X.shape[0]*rate):]\n",
    "    return train, val\n",
    "\n",
    "def periods(data,days,data_date=None,f_days=5):\n",
    "    y = []\n",
    "    x = []\n",
    "    p_dates = []\n",
    "    for i in range(0,len(data),days):\n",
    "        if i+days+f_days>=len(data)-1:\n",
    "            break\n",
    "        x.append(data[i:i+days])\n",
    "        if type(data_date) != type(None):\n",
    "            p_dates.append(data_date[i:i+days])\n",
    "            #print(p_dates[-1])\n",
    "        if data[i+days+f_days][0] > data[i+days-1][0]:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "        #print(data_date[i+days-1],data_date[i+days+f_days])\n",
    "    return np.array(x),np.array(y),p_dates\n",
    "def unperiods(data,days):\n",
    "    l = []\n",
    "    for a in data:\n",
    "        l.extend(a)\n",
    "    return l\n",
    "df = pd.read_csv(\"data/indicators/2330_indicators.csv\").drop(range(11))\n",
    "print(np.array(df.values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 20, 9)\n"
     ]
    }
   ],
   "source": [
    "p_days = 20\n",
    "sc = MinMaxScaler()\n",
    "#移除前11筆因累積計算技術指標為0\n",
    "data_sc = sc.fit_transform(df.drop(['date'],axis=1).values)\n",
    "x,y,p_dates = periods(data_sc,p_days,df.iloc[:,[0]].values)\n",
    "print(x.shape)\n",
    "X_train , X_val = splitData(x,0.8)\n",
    "Y_train , Y_val = splitData(y,0.8)\n",
    "xx,pd = splitData(np.array(p_dates),0.8)\n",
    "p_date = unperiods(pd,p_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 20, 32)            5376      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 20, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,049\n",
      "Trainable params: 22,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 380\n",
    "batch_size = 16\n",
    "LSTM_num = 3\n",
    "units = 32\n",
    "\n",
    "model_lstm = Sequential()\n",
    "#use L2 to improve overfit\n",
    "model_lstm.add(LSTM(units,input_shape=X_train.shape[1:],activation='relu',kernel_initializer='random_uniform',return_sequences=True)) \n",
    "#model_lstm.add(Dropout(0.1))\n",
    "\n",
    "model_lstm.add(LSTM(units,activation='relu',return_sequences=True))\n",
    "#model_lstm.add(Dropout(0.001))\n",
    "\n",
    "model_lstm.add(LSTM(units,activation='relu',return_sequences=False))\n",
    "model_lstm.add(Dropout(0.1))\n",
    "\n",
    "model_lstm.add(Dense(1,activation='sigmoid'))\n",
    "model_lstm.summary()\n",
    "model_lstm.compile(loss='binary_crossentropy',optimizer=\"Adam\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 264 samples, validate on 67 samples\n",
      "Epoch 1/380\n",
      "264/264 [==============================] - 2s 6ms/step - loss: 0.6933 - acc: 0.4735 - val_loss: 0.6932 - val_acc: 0.4925\n",
      "Epoch 2/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5076 - val_loss: 0.6932 - val_acc: 0.5075\n",
      "Epoch 3/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.5076 - val_loss: 0.6932 - val_acc: 0.5075\n",
      "Epoch 4/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5038 - val_loss: 0.6932 - val_acc: 0.5075\n",
      "Epoch 5/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5076 - val_loss: 0.6933 - val_acc: 0.5075\n",
      "Epoch 6/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6936 - acc: 0.5038 - val_loss: 0.6934 - val_acc: 0.5075\n",
      "Epoch 7/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.4848 - val_loss: 0.6934 - val_acc: 0.4776\n",
      "Epoch 8/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5038 - val_loss: 0.6934 - val_acc: 0.4925\n",
      "Epoch 9/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5076 - val_loss: 0.6934 - val_acc: 0.4925\n",
      "Epoch 10/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5038 - val_loss: 0.6934 - val_acc: 0.5075\n",
      "Epoch 11/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.5076 - val_loss: 0.6937 - val_acc: 0.4627\n",
      "Epoch 12/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5114 - val_loss: 0.6941 - val_acc: 0.5075\n",
      "Epoch 13/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5114 - val_loss: 0.6942 - val_acc: 0.4627\n",
      "Epoch 14/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.4924 - val_loss: 0.7073 - val_acc: 0.4925\n",
      "Epoch 15/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5038 - val_loss: 0.6948 - val_acc: 0.4627\n",
      "Epoch 16/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5152 - val_loss: 0.6955 - val_acc: 0.4627\n",
      "Epoch 17/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5265 - val_loss: 0.7000 - val_acc: 0.5075\n",
      "Epoch 18/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5076 - val_loss: 0.7437 - val_acc: 0.4925\n",
      "Epoch 19/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5417 - val_loss: 0.7044 - val_acc: 0.4627\n",
      "Epoch 20/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5114 - val_loss: 0.9510 - val_acc: 0.5075\n",
      "Epoch 21/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.5076 - val_loss: 0.6992 - val_acc: 0.4925\n",
      "Epoch 22/380\n",
      "264/264 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.4924 - val_loss: 0.7032 - val_acc: 0.4627\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "#decay lr by half every 10 epoch\n",
    "#lrate = LearningRateScheduler(step_decay)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "history = model_lstm.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, shuffle=False,validation_data=(X_val,Y_val),callbacks=[early_stop])\n",
    "y_pred_test_lstm = model_lstm.predict(X_val)\n",
    "y_train_pred_lstm = model_lstm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4898236082358794\n"
     ]
    }
   ],
   "source": [
    "y_preds= model_lstm.predict(X_val)\n",
    "print(np.mean(history.history['val_acc']))\n",
    "#accuracy when the predictions which is bigger than threshold and equal to y\n",
    "def acc_threshold(preds,rate):\n",
    "    re = []\n",
    "    for i,y in enumerate(preds):\n",
    "        if y > rate:\n",
    "            y=1\n",
    "        else:\n",
    "            y=0\n",
    "        if Y_val[i]==y:\n",
    "            re.append(1)\n",
    "        else:\n",
    "            re.append(0)\n",
    "    return np.mean(re)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = []\n",
    "for i in np.arange(0.5,1,0.05):\n",
    "    thresholds.append(np.round(acc_threshold(y_preds,i),decimals=2))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(np.arange(0.5,1,0.05),thresholds,'b',label='Thresholds')\n",
    "plt.title('Accuracy by threshold',)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Rate')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Rate Of Return\n",
    "x: trended data\n",
    "y: predictions\n",
    "r: trade if y > r\n",
    "p: period\n",
    "s: short if y < r\n",
    "\"\"\"\n",
    "def ROR(x,y,r,p,init_funds,s=False):\n",
    "    dict_Info = {\n",
    "        'total_costs':[],\n",
    "        'total_prices':[],\n",
    "        'trade_times':[],\n",
    "        'date_msg':[],\n",
    "        \"RORs\":[]\n",
    "    }\n",
    "    funds = init_funds\n",
    "    profit=0\n",
    "    total_cost=0\n",
    "    total_price=0\n",
    "    acc = []\n",
    "    times = 0\n",
    "    d_msg = ''\n",
    "    for i,pre in enumerate(y[:-1]):\n",
    "        price = x[(i+1)*p_days][0]\n",
    "        cost = x[i*p_days][0]\n",
    "        quantity = int(funds/cost)\n",
    "        if pre>r:\n",
    "            times+=1\n",
    "            total_cost+= cost * quantity\n",
    "            total_price+= price  * quantity\n",
    "            funds+= (price-cost)*quantity            \n",
    "            d_msg += \"\\nBuy Date: {} - {}\\nSell Date: {} - {}\\nQuantity: {}\\n\".format(p_date[i*p_days],cost,p_date[(i+1)*p_days],price,quantity)\n",
    "            if price > cost:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "        elif s:\n",
    "            times+=1\n",
    "            total_cost+= price * quantity\n",
    "            total_price+= cost * quantity\n",
    "            funds+= (cost-price) * quantity\n",
    "            pass\n",
    "        if (i+1)%p==0:\n",
    "            #pass and not record the rate of prediciotn 'pre' < rate of threshold 'r'\n",
    "            if total_cost != 0:\n",
    "                dict_Info['total_costs'].append(total_cost*1000)\n",
    "                dict_Info['total_prices'].append(total_price*1000)\n",
    "                dict_Info['trade_times'].append(times)\n",
    "                dict_Info['date_msg'].append(d_msg)\n",
    "                dict_Info['RORs'].append((funds)/init_funds)\n",
    "            times=0\n",
    "            funds = init_funds\n",
    "            total_cost=0\n",
    "            total_price=0\n",
    "            d_msg = ''\n",
    "    #in case that dont have enough tra\n",
    "    if len(dict_Info['RORs']) ==0:\n",
    "        dict_Info['total_costs'].append(total_cost*1000)\n",
    "        dict_Info['total_prices'].append(total_price*1000)\n",
    "        dict_Info['trade_times'].append(times)\n",
    "        dict_Info['date_msg'].append(d_msg)\n",
    "        dict_Info['RORs'].append((funds)/init_funds)\n",
    "    if len(acc) == 0:\n",
    "        return 'No Deals.'\n",
    "    print(\"Trend Accuracy:\",np.mean(acc))\n",
    "    return dict_Info,init_funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-17b1333cc899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munperiods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_test_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RORs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     msg = '{}\\nTotal Costs: {}\\nTrade Times: {}\\nInitial Funds: {}\\nProfits: {}\\nReturn Of Rate: {}\\n'.format(d['date_msg'][i],\n\u001b[1;32m      5\u001b[0m                                                                                     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_costs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "d,funds = ROR(sc.inverse_transform(unperiods(X_val,p_days)),y_pred_test_lstm,0.5,12,1000)\n",
    "\n",
    "for i in range(len(d['RORs'])):\n",
    "    msg = '{}\\nTotal Costs: {}\\nTrade Times: {}\\nInitial Funds: {}\\nProfits: {}\\nReturn Of Rate: {}\\n'.format(d['date_msg'][i],\n",
    "                                                                                    d['total_costs'][i],\n",
    "                                                                                     d['trade_times'][i],\n",
    "                                                                                    funds*1000,\n",
    "                                                                                     d['total_prices'][i]-d['total_costs'][i],\n",
    "                                                                                     d['RORs'][i])\n",
    "    print(msg)\n",
    "print(\"Average of Years ROR: {:.3f}\".format(np.mean(d['RORs'])))\n",
    "#print(\"Total cost: {:.2f}\\nProfits:{:.2f}\\nReturn of Rate:{:.2f}\".format(t,p,p/t*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
