{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from os import mkdir\n",
    "from os.path import isdir\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "class Crawler():\n",
    "    def __init__(self,dir='data/chips'):\n",
    "        # save in directory 'data'\n",
    "        if not isdir(dir):\n",
    "            mkdir(dir)\n",
    "        self.dir = dir\n",
    "    \n",
    "    def writeCSV(self,file,rows):\n",
    "        with open(\"{}/{}.csv\".format(self.dir,file),'w',encoding='utf-8') as f:\n",
    "            writer = csv.writer(f,lineterminator='\\n')\n",
    "            writer.writerows(rows)\n",
    "\n",
    "    def getChipByDate(self,date,file):\n",
    "        twse = \"https://www.twse.com.tw/fund/T86\"\n",
    "        para = {\n",
    "            'response' : 'csv',\n",
    "            'date' : date,\n",
    "            'selectType' : 'ALL'\n",
    "        }\n",
    "        try:\n",
    "            result = requests.get(twse,params=para)\n",
    "        except BaseException:\n",
    "            return date+'Connection fail!'\n",
    "        if not result.ok:\n",
    "            return date+'Connection fail!'\n",
    "        if len(result.text) < 10:\n",
    "            return date+' No DATA!'\n",
    "        rows = result.text.replace('\\r','').split('\\n')\n",
    "        r_rows = [['#==#'+date]]\n",
    "        for i in range(len(rows)):\n",
    "            #row cleanup and split\n",
    "            row = re.sub('[,\"=]','',rows[i].replace(',\"','_')).replace('_',',').split(',')\n",
    "            if (re.search(r'[^A-Za-z0-9]+',row[0]) == None) and (len(row) != 1):\n",
    "                r_rows.append(row)\n",
    "        self.writeCSV(file,r_rows)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import csv\n",
    "oneday = timedelta(days=1)\n",
    "date = datetime(2019,10,9)\n",
    "final = datetime(2012,5,2)\n",
    "file = str(date)[:10].replace('-','')\n",
    "\n",
    "while(date>final):\n",
    "    c = Crawler()\n",
    "    ds = str(date)[:10].replace('-','')\n",
    "    s = c.getChipByDate(ds,'days/{}'.format(ds))\n",
    "    if s != None:\n",
    "        print('{} - Skipped'.format(str(date)[:10]))\n",
    "    else:\n",
    "        print('{} - complete'.format(str(date)[:10]))\n",
    "    time.sleep(1.2)\n",
    "    date -= oneday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "startIndex =0\n",
    "endIndex = 1000000\n",
    "total_index = 0\n",
    "s_dates = ''\n",
    "with open('data/chips/20191009.csv','rb') as fin:\n",
    "    while(1):\n",
    "        fin.seek(startIndex,0)\n",
    "        #print(fin.tell())\n",
    "        data = fin.read(endIndex)\n",
    "        rows=''\n",
    "        try:\n",
    "            rows = data.decode('utf-8').split('#==#')[1]\n",
    "        except UnicodeDecodeError as err:\n",
    "            endIndex-=1\n",
    "            continue\n",
    "        except IndexError as ierr:\n",
    "            break\n",
    "        startIndex += len(rows.encode('utf-8'))+4\n",
    "        if len(rows) <= 10:\n",
    "            continue\n",
    "        ss = rows.split('\\n')\n",
    "        if len(ss)>2:\n",
    "            s_dates += ss[0]\n",
    "print(s_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawl from today\n",
    "oneday = timedelta(days=1)\n",
    "date = datetime.today()\n",
    "final = datetime(2012,5,2)\n",
    "file = str(date)[:10].replace('-','')\n",
    "while(date>final):\n",
    "    if str(date)[:10].replace('-','') in s_dates:\n",
    "        print(str(date)+'  exist')\n",
    "        date -= oneday \n",
    "        continue\n",
    "    c = Crawler()\n",
    "    ds = str(date)[:10].replace('-','')\n",
    "    input()\n",
    "    s = c.getChipByDate(ds,'days/{}'.format(file))\n",
    "    print('{} - complete'.format(str(date)[:10]))\n",
    "    time.sleep(1.2)\n",
    "    date -= oneday    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check and crawl from indicators\n",
    "import pandas as pd\n",
    "import os\n",
    "def minguo2Date(ming):\n",
    "    y , m , d = ming.split('/')\n",
    "    return str(int(y)+1911)+m+d\n",
    "exdays = ''\n",
    "for f in os.listdir('data/chips/days'):\n",
    "    exdays += f[:-4]\n",
    "oneday = timedelta(days=1)\n",
    "date = datetime.today()\n",
    "final = datetime(2012,5,2)\n",
    "file = str(date)[:10].replace('-','')\n",
    "df = pd.read_csv('data/indicators/2317_indicators.csv')\n",
    "dist_days = df.iloc[:,0]\n",
    "index=0\n",
    "for i,d in enumerate(dist_days.values):\n",
    "    if minguo2Date(d) == '20120502':\n",
    "        index = i\n",
    "dist_days = dist_days.iloc[index:].values\n",
    "for d in dist_days:\n",
    "    d = minguo2Date(d)\n",
    "    if d in exdays:\n",
    "        continue\n",
    "    c = Crawler()\n",
    "    s = c.getChipByDate(d,'days/{}'.format(d))\n",
    "    if s != None:\n",
    "        print('{} - Skipped'.format(d))\n",
    "    else:\n",
    "        print('{} - complete'.format(d))\n",
    "    time.sleep(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data from daily file by stock number\n",
    "stock_no = '23172330'\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "path = 'data/chips/days/'\n",
    "flag = True\n",
    "for f in os.listdir(path):\n",
    "    rows = []\n",
    "    with open(path+f,'r',encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for r in reader:\n",
    "            rows.append(str(r))\n",
    "        date = rows[0][6:-2]\n",
    "        for row in rows:\n",
    "            cols = [date]\n",
    "            r = re.sub(\"[ \\[\\]\\r']\",'',row).split(',')\n",
    "            if re.search(r'[^A-Za-z0-9]+',r[0]) != None:\n",
    "                continue\n",
    "            #write only needed\n",
    "            if not (r[0] in stock_no):\n",
    "                continue\n",
    "            stockno = r[0]\n",
    "            cols.extend(r[2:])\n",
    "            with open('data/chips/chips_{}.csv'.format(stockno),'a') as f:\n",
    "                writer = csv.writer(f,lineterminator='\\n')\n",
    "                writer.writerow(cols)\n",
    "        print(date+' -- Written!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
